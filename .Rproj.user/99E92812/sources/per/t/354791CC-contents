---
title: "PHARMACEUTICAL BIOSTATISTICS (PHC410)"
subtitle: "Introduction to Big Data <br>&<br>Data Analytics"
author: "Dr Yuslina Zakaria"
institute: "Faculty of Pharmacy, UiTM Selangor"
date: "`r gsub(' 0', ' ', format(Sys.Date(), format='%b %d, %Y'))`<br>Updated: Nov 5, 2019"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: ["default","rladies","rladies-fonts"]
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
bibliography: bib.bib
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
#to install xaringan
#install.packages("devtools")
#devtools::install_github("yihui/xaringan")
library(png)
library(kableExtra)
library(ggplot2)
library(grid)
library(gridExtra)
library(RefManageR)
library(tidyverse)
library(data.table)
knitr::write_bib(x = "rmarkdown", file = "bib.bib")
```
```{r xaringan-theme, include=FALSE}
library(xaringanthemer)
write_xaringan_theme(
   background_color = "white"
)
mono_light(
   base_color = "#1c5253",
  header_font_google = google_font("Josefin Sans"),
  text_font_google   = google_font("Montserrat", "300", "300i"),
  code_font_google   = google_font("Droid Mono"),
  extra_css = list(".small" = list("font-size" = "50%"))
)
```

# Learning Outcomes

At the end of this lesson, students should be able to:

1. describe the big data, data science and related concepts. 

2. describe the application of data science in related fields and healthcare.

3. differentiate between statistical analysis, data analysis and big data analytics.

4. describe the data analysis workflow and the principles of tidy data.

5. explain the types of big data analytics.

---

# Outlines


- Introduction to Big Data

- What is Data Science?

- Related Concepts and Applications in Data Science

- Statistical Analysis VS Data Analysis

- The Workflow of Data Analysis

- The Principles of *Tidy Data*

- Big Data Analytics & The Types of Data Analytics
---

class: inverse, center, middle

# BIG DATA

---
class: inverse, center, middle

# BIG DATA
## Introductory video: Big Data - Tim Smith

---
# The V's of Big Data

```{r echo=FALSE,fig.align='center',out.width="100%"}
knitr::include_graphics('figure/bigdataV.png')
```
---
# The 8V's of Big Data

```{r echo=FALSE,fig.align='center',out.width="70%"}
knitr::include_graphics('figure/the-8-vs-of-big-data.png')
```
---

# The 4V's of Big Data

```{r echo=FALSE,fig.align='center',out.width="100%"}
knitr::include_graphics('figure/ibmbigdata.jpg')
```
---

# The 4 main V's of Big Data

## 01 Volume
.pull-left[
- The **size** of the data

What is Big Data
- Terrabytes to 10s of petabytes of the storage system

What is not Big Data
- A few gigabtes

]
.pull-right[
```{r echo=FALSE}
knitr::include_graphics('figure/Volume.jpg')
```
.small[source: IBM]
]
---
# The 4 main V's of Big Data

## 02 Variety
.pull-left[
- The different **types** of data

What is Big Data?
- Use data from multiple sources and in multiple forms
- Involved **unstructured**, **semi-structured** and **structured** data
]
.pull-right[
```{r echo=FALSE}
knitr::include_graphics('figure/Variety.jpg')
```
<font size="2">source: IBM</font>
]
---

# The 4 main V's of Big Data

## 02 Variety

- Structured data
   -  Like tables with fixed attributes/variables
   -  Traditionally handled by relational databases
   
- Unstructured data
   -  Usually generated by humans
   -  E.g. natural language, voice, Wikipedia, Twitter posts
   -  Must be processed into (semi-structured) data to gain value
   
- Semi-structured data
   -  Has some structure in tags but it changes with documents
   -  Examples: HTML, XML, JSON files, server logs

---
# The 4 main V's of Big Data

## 02 Variety
### Data Sources
- Enterprise data
   -  Customer information
   -  Transactions, e.g. purchases
- Experimental/Observational Data (EOD)
   -  Created by machines from sensors/devices
   -  Trading systems, satellites
   -  Microscopes, video streams, smart meters
- Social media
   -  Created by humans
   -  Messages, posts, blogs, Wikis

---
# The 4 main V's of Big Data

## 03 Velocity
.pull-left[
- Data Volume per time
- The speed and frequency at which the data is generated, captured and shared
- The velocity of large data streams power the ability to parse text, detect sentiment and identify new patterns.

What is Big Data
- 30 KiB to 30 GiB per second (902 GiB/year to 902 PiB/year)

What is not Big Data
- A never changing data set

]
.pull-right[
```{r cache=FALSE}
knitr::include_graphics('figure/Velocity.jpg')
```
<font size="2">source: IBM</font>
]

---

# The 4 main V's of Big Data

## 04 Veracity

The trustworthiness of the data in terms of accuracy
.pull-left[
- Data involves some uncertainty and ambiguities
- Mistakes can be introduced by human and machines
- Examples: 
  -  People sharing accounts
  - Like sth today, dislike it tomorrow
  - Wrong system timestamps
Data Quality is vital!
- Analytics and conclusions rely on good data quality
- GIGO paradigm: *Garbage In - Garbage Out

]
.pull-right[
```{r }
knitr::include_graphics('figure/Veracity.jpg')
```
<font size="2">source: IBM</font>
]


---
# The Other Vs of Big Data

## Value
Insights gained from data

.pull-left[
- Just having Big Data is of no use unless we can turn it into a value or make it useful

What is Big Data?

-  Raw data of Big Data is of low value
   -  For example, single observations may not bring any value
-  Analytics and theory about the data increases the value
   -  Analytics transform big data into smart (valuable) data!

]
.pull-right[
```{r echo=FALSE}
knitr::include_graphics('figure/smart-data.jpg')
```
]

---

# The Other Vs of Big Data

## Visualisation
.pull-left[
- Represents data in a visual context by making explicit the trends and patterns inherent in the data.
- Allows users to make sense of the data.
- Visualising incomplete data will render half-baked, obsolete, or erroneous visualisation.
]
.pull-right[
```{r echo=FALSE}
knitr::include_graphics('figure/visualisation.png')
```
<font size="2">Don't trust everything you see, even salt looks like sugar</font>
]
---

class: inverse, center, middle

# DATA SCIENCE
## An Introduction
---

# What is Data Science?
.pull-left[
- Data science is the science of data. 

- To explain processes and objects through the available data. The explanation is expected to be objective and accurate enough to make predictions. 

- The ultimate goal of the explanations is to make informed decisions based on the knowledge extracted from the underlying data.
]
.pull-right[
```{r echo=FALSE}
knitr::include_graphics('figure/datascientist.jpg')
```
]

---
class: inverse, center, middle

# DATA SCIENCE
## Related Concepts
---

# Artificial Intelligence (AI)
- The term was first coined in 1956.

- The simulation of human intelligence processes by machines, especially computer systems. These processes include learning (the acquisition of information and rules for using the information), reasoning (using rules to reach approximate or definite conclusions) and self-correction. 

- Particular applications of AI include expert systems, speech recognition and machine vision.
---
class: inverse, center, middle

# MACHINE LEARNING
## Introductory video: What is Machine Learning?

---

# Machine Learning
- A branch of AI based on the idea that systems can learn from data, identify patterns and make decisions with minimal human intervention.

- It gives computers the capability to learn without being explicitly programmed.

- Performs a specific task without using explicit instructions, however relying on patterns and inference using computational algorithms and statistical models.

- Provides methods for building intelligent systems and also for improving the performance of existing systems.

---
# Machine Learning Workflow
```{r echo=FALSE,fig.align='center',out.width="70%"}
knitr::include_graphics('figure/ML.png')
```

---
# Machine Learning Concepts
## Supervised

.pull-left[
- set of examples (the training set) is submitted during the training phase.
- each input is labeled with a desired output value.
- Techniques: Regression (continuous) and Classification (categorical) 
- e.g: mail spam detector - the algorithm was trained with some spam, not spam emails and which group they belong. This trainig process continue when you mark a mail as "spam" or "not spam" from the spam folder.
]
.pull-right[
```{r echo=FALSE}
knitr::include_graphics('figure/SL-scheme.jpeg')
```
]
---
# Machine Learning Concepts
## Unsupervised
.pull-left[
- The training examples provided by the system are not labelled with the belonging class.
- The system develops and organise data, searching common characteristics among them, and changing based on internal knowledge.
- e.g. clustering - algorithm try to put similar things in a cluster and dissimilar in a different cluster, and the concept of similarity depends on a similarity measure.
- Algorithms:  k-means
]
.pull-right[
```{r echo=FALSE}
knitr::include_graphics('figure/USL-scheme.jpeg')
```
]
---
# Machine Learning Concepts
## Deep Learning
.pull-left[
- Based on the way the human brain process information and learns.
- It consists of ML model composed by a several levels of representation, in which every level use the informations from the previous level to learn deeply.
- Allows the model to first learn very simple representations in the first layer which are then combined into more and more complex and abstract representations for each layer.
- Usually used on images.
]
.pull-right[
```{r echo=FALSE}
knitr::include_graphics('figure/DL-scheme.jpeg')
```
]
---
# Machine Learning Concepts
## Reinforcement Learning
.pull-left[
- It is an autonomous, self teaching system that essentially learns by trial and error.
- This is similar to how we learn by experience e.g riding a bicycle.
- Computers try different actions, learn from the feedback whether the action delivered a better result, and reinforce the actions that worked.
- e.g. Robot learning how to walk
]
.pull-right[
```{r echo=FALSE,out.width="70%"}
knitr::include_graphics('figure/robotwalk.jpg')
```
]
---
# Model Evaluation
- to evaluate the built model to check how well it performs on unseen examples, that is, how well it generalises the training dataset.

- Regression 

  -   Coefficient of determination (R2) - the closer to 1 the better
  
  -   Mean square error (MSE) - the closer to 0 the better
  
  -   Root Mean square error (RMSE) - the closer to 0 the better
  
---
# Model Evaluation
## Classification

.pull-left[
- Classification

  -  Precision
  
  -  Recall (sensitivity)
  
  -  F-score (harmonic mean of precision and recall)
     $$F=2 * \frac{Precision * Recall}{Precision + Recall}$$
 ]
.pull-right[
```{r echo=FALSE}
knitr::include_graphics('figure/CM-table.jpg')
```
]
---
#Model Evaluation
## Clustering
- Rand Index (RI) is a **metric for external evaluation**.

- It compares the predicted clusters to the real clusters (manually assigned by an expert user), and it is similar to the accuracy metric for supervised algorithms.
- The formula for Rand index is

$$r=\frac{TP + TN}{TP + FN + FP + FN}$$
---

class: inverse, center, middle

# DATA SCIENCE
## The Applications
---
# Data Science
## Related Areas of Applications

1. Banking

2. Finance

3. Manufacturing

4. Transport

5. E-commerce

6. Healthcare

---
# Data Science in Healthcare

- Health data can be reused for research with numerous applications from identification of novel genotype–phenotype associations to building predictive models of disease progression. 

```{r echo=FALSE,fig.align='center',out.width="100%"}
knitr::include_graphics('figure/bigdatahealth.png')
```
<font size="2">Big Data Drug Discovery (Brown et al. 2018)</font>

---
# Data Science in Healthcare
## 01 Association Mining
-  Derive clinically relevant insights into human diseases and treatment effects.

-  Example of mining associations relevant to drug discovery is in studying **disease comorbidities** - quantifying disease co-occurrence across very large cohorts.

-  Data mining methods have been applied to filter out spurious correlations and identify relevant associations between conditions. 

-  Mined disease associations can subsequently be analysed and visualised in the form of comorbidity networks, whose structure has been shown to be relevant for the understanding of disease progression.

---
# Data Science in Healthcare
## 02 PheWAS 

-  Phenotypic profiles linked to genetic data provide novel **phenotype-genotype associations** with numerous application in drug discovery.

-  Phenotypes enable association finding between known genetic factors and novel disease conditions.

-  Help identify drug repurposing hypotheses, discover novel drug targets, validate existing ones, provide insights to disease aetiology and help explain adverse drug reactions.

-  MedWAS has been proposed to capture associations between genetic variants and drug efficacy and side effects of various doses.

---
# Data Science in Healthcare
## 03 Pharmacogenomics 

-  The study of **how genes affect a person's response to particular drugs**.

-  Linked health and genotype data offer an opportunity to identify novel pharmacogenetic variants that have an impact on treatment effects including drug efficacy, safety and metabolism.

-  Allow for correlation of patient drug exposure and therapeutic response data, and subsequent mining enables associations in underlying genotypes to be exposed.

-  Better understanding of pharmacogenomic variation will enable more individualised treatment selection and dosing.

---
# Data Science in Healthcare
## 04 Pharmacovigilance
.pull-left[
-  Adverse events databases rely solely on voluntary reporting.

-  EHRs mining and social media datasets for pharmacovigilance enables the detection of signals closer to real time and overcomes the problems of reporting bias, underreporting and lack of denominators (or sample sizes) needed to quantify the prevalence of ADEs.
]
.pull-right[
```{r echo=FALSE,fig.align='center'}
knitr::include_graphics('figure/pharmacovigilance.png')
```
]
---

# Data Science in Healthcare
## 04 Pharmacovigilance

-  LePendu et al. (2013) reported a scalable pharmacovigilance workflow involving processing clinical narratives of 1.8 million patients.

-  Findings: the majority of the investigated adverse drug reactions could have been identified earlier than the official alert using the EHR mining approach. 

-  In addition, the authors were able to estimate the prevalence of ADEs due to drug–drug interactions.


```{r echo=FALSE,fig.align='center',out.width="50%"}
knitr::include_graphics('figure/lependu.jpg')
```

---

# Data Science in Healthcare
## 05 Predictive Modelling
- Predict the **outcome of disease given the historical data** of the patients.

- The computational model can be trained to predict clinical outcomes to **identify early symptoms of serious conditions** and to **find patients at high risk of developing diseases**, as a basis for personalised decision making.

- Enable practitioners to analyse data, make correlations between variables and provide insights to doctors and medical practitioners.

- A variety of supervised machine learning algorithms have also been successfully employed to predict disease progression, survival rates and future clinical events. 

---
# Data Science in Healthcare
## 06 Cohort Querying

- Solve problems in **finding a sufficient number of eligible participants** with similar characteristics.

- TrialX is a computerised system that matches patients with trials based on their health records for clinical trial recruitment.

- EHR4CR uses deidentified EHR data from hospital across Europe to assess trial feasibility and number of eligible patients across sites.

- The system allows participating hospitals to efficiently deanonymise data and contact eligible patients for trial recruitment.

---
# Data Science in Healthcare
## 07 Patient Stratification

-  A large collection of searchable clinic profiles can be used to divide patients into subgroups with similar phenotypic characteristics and prognosis.

-  A variety of supervised machine learning (ML) approaches have been employed for this task. 

-  Unsupervised ML have been also applied to tackle unstructured clinical narratives.

---
# Data Science in Healthcare
## 08 Personalised Medicine or Precision Medicine

-  Personalised Medicine is frequently misintrepreted as the creation of drugs or medical devices that are unique to a patient. 

-  Precision Medicine focuses on classifying individuals into subpopulations that differ in their susceptibility to a particular diseases or response to a specific treatment.

-  And thus identify which approaches will be effective for the subpopulations of patients.

-  Using multiple data types, including genetic biomarkers, pharmacogenomic variants, physiological measurements and enviromental exposures and also lifestyle factors.

---
# 08 Personalised Medicine or Precision Medicine
## The Benefits

- Allow identification of subpopulations of patients that would benefit from a therapy and those for whom it would be ineffective or even harmful.

- Used **for disease treatment and prevention**.

- Improves the ability to prevent disease, promote health, and reduce health disparities in populations by applying emerging methods and technologies for measuring disease, pathogens, exposures, behaviours, and susceptibility in populations.

- The decision is used to **develop policies and targeted implementation programs** to improve health.
---

# Other Applications in Healthcare
## Medical Imaging
-  Analysing X-rays, MRIs, CT-Scans

-  Automatically detect flaws or microscopic deformities in the imagery. 

-  Using image recognition tools to understand complex medical imagery.

-  Research team in US produced software that recognizes minute features in pathology image of ER+ breast cancer to determine which patients need chemotheraphy and which could be better treated by hormonal theraphy.

```{r echo=FALSE,,out.width="40%",fig.align="right",fig.show="asis"}
knitr::include_graphics('figure/mri_168715138.jpg')
```
---
# Other Applications in Healthcare
## Genomics
.pull-left[
-  Genomics, emerged in the 80s at the confluence of genetics, statistics and large-scale datasets.
   -  Analyse genomic strands and search for irregularities and defects in it, and find connections between genetic and health condition of the person.
- MapReduce has significantly reduced the processing time for genome sequencing.
- Able to detect the trigger or risk factors in individual genetic data allowing prevention and avoidance of serious chronic disease.
]
.pull-right[
```{r echo=FALSE}
knitr::include_graphics('figure/genome.jpg')
```
]
---
# Other Applications in Healthcare
## Drug Discovery

- simplifying the time-consuming and complex process.

- provide early insight and increases the success rate of predictions of newly discovered drug.

- analyse several combinations of drugs and their effect on different gene structure to predict outcome.

- simulate how the drugs will act in the human body that takes the long laboratory experimentations.
---
# Other Applications in Healthcare
## Monitoring Patient Health

- Via electronic health records (EHRs) and telemedicine.

- EHRs store crucial patient information including their medical history, results of lab tests, demographic detail and etc. These data enable doctors to get a clear picture of patient history and thus facilitate better and timely delivery of healthcare services.

- Data collected from digital devices and technological innovations can be easily shared which makes diagnosis a lot easier. 

- Big data helps predicting acute medical events and prevent deterioration of patient's conditions.

---
# Other Applications in Healthcare
## Providing Virtual Assistance (Healthbots)

- Intelligent bots that answer to user queries have been created using NLP.

- In healthcare sector, healthbots are used to answer questions from patients and provide them with proper diagnostic guidelines.
   
---
class: inverse, center, middle

# STATISTICAL ANALYSIS vs DATA ANALYSIS
---

# STATISTICAL ANALYSIS VS DATA ANALYSIS
## The difference

- Both are used hand in hand to solve problems.

- Statistical analysis

   -  applies statistical methods to **gain understanding of a larger population** by analysing the information of a sample.
   -  allows **inferences and prediction** of the behaviour and characteristics of population from a sample
   
- Data analysis 

   -  includes process of **inspecting, cleaning, transforming, modeling, presenting and reporting data** into useful information.
   -  the process can be used as an **input into performing statistical analysis**.
   -  one of the techniques is **Data Analytics**.
   
---
class: inverse, center, middle

# DATA ANALYSIS
---

# Data Analysis
## Data Analysis Workflow
```{r echo=FALSE,fig.align='center',out.width="100%"}
knitr::include_graphics('figure/DA-workflow.png')
```
Source: Hadley Wickham (Data Analysis using R)

---
# Data Analysis Workflow
## Data Wrangling
```{r echo=FALSE,fig.align='center',out.width="80%"}
knitr::include_graphics('figure/datawrangling.png')
```
- process of importing, cleaning and transforming raw data into actionable information for analysis.
- takes up about 60-80% of the time.
- *Import*
   -  Take data stored in in a file, database, web API, and load it.
- *Tidy*
   -  The cleaning phase may take up to 80% of the time.
- *Transform*
   -  Changing the values of observations through computational or mathematical operation.

---
# Data Wrangling
## Importing Data
.pull-left[
- Import data to be used for analysis.

- May involve single or multiple datasets.

- May include structured, semi-structured or unstructured dataset.
]
.pull-right[
```{r echo=FALSE}
knitr::include_graphics('figure/data.png')
```
]
---
class: inverse, center, middle

# DATA CLEANING & TRANSFORMATION
## The Why's
---
# Data Cleaning & Transformation
## Better data beats fancier algorithms.
.pull-left[
- Garbage in garbage out.
- Proper data does not need complex processing to find insights.
 ]
.pull-right[
```{r echo=FALSE}
knitr::include_graphics('figure/gigo.png')
```
.small[source: https://elitedatascience.com/]
]
---
# Data Cleaning & Transformation
## Remove unwanted observations
- Removing **duplicate** and **irrelevant** information.
.pull-left[
- Duplicate observations most frequently arise during data collection, such as when you:
   -  Combine datasets from multiple places
   -  Scrape data
   -  Receive data from clients/other departments
 ]
.pull-right[
```{r echo=FALSE}
knitr::include_graphics('figure/duplicate.png')
```
.small[source: https://elitedatascience.com/]
]
---
# Data Cleaning & Transformation
## Remove unwanted observations
- Removing **duplicate** and **irrelevant** information.
.pull-left[
-  Irrelevant observations are those that don’t actually fit the specific problem that you’re trying to solve.
  -  For example, if you were building a model for Single-Family homes only, you wouldn't want observations for Apartments in there.
  -  Visualising the data is a great way to pull out the unwanted data. 
 ]
.pull-right[
```{r echo=FALSE}
knitr::include_graphics('figure/irrelevant.png')
```
.small[source: https://elitedatascience.com/]
]
---
# Data Cleaning & Transformation
## Fix structural errors

- Structural errors are those that arise during measurement, data transfer, or other types of **poor housekeeping.**
- For example: Check for typos or inconsistent capitalization especially for categorical features.

.pull-left[
```{r echo=FALSE,fig.cap="Before",fig.align='center'}
knitr::include_graphics('figure/before.png')
```
.small[source: https://elitedatascience.com/] ]
.pull-right[
```{r echo=FALSE,fig.cap="After",fig.align='center'}
knitr::include_graphics('figure/after.png')
```
]

---

# Data Cleaning & Transformation
## Filter unwanted outliers

.pull-left[
- Outliers can cause problems with certain types of models. 

- If you have a legitimate reason to remove an outlier, it will help your model’s performance.

- However, outliers are *innocent until proven guilty*. You should never remove an outlier just because it’s a **big number**. That big number could be very informative for your model.
]
.pull-right[
```{r echo=FALSE}
knitr::include_graphics('figure/outlier.png')
```
.small[source: https://elitedatascience.com/]
]

---

# Data Cleaning & Transformation
## Handle missing data

.pull-left[
- You cannot simply ignore missing values in your dataset! 

- Must handle in some way as most algorithms do not accept missing values.

- Most recommended ways to deal with missing data:
   -  Drop the observations
      -  When you drop observations, you drop information.
   -  Impute the missing values
      -  Missingness is almost always informative itself.
]
.pull-right[
```{r echo=FALSE}
knitr::include_graphics('figure/missing.png')
```
]
.small[source: https://elitedatascience.com/]
---
# Tidy Data
## The principles

   1. Each variable must have its own column.
   
   2. Each observation must have its own row.
   
   3. Each value must have its own cell.

```{r echo=FALSE}
knitr::include_graphics('figure/tidydata.png')
```
---
#Tidy Data
## The principles
1. Each variable must have its own column.

```{r echo=FALSE, fig.cap="Messy data",fig.align='center',out.width="80%"}
knitr::include_graphics('figure/untidy1.png')
```

```{r echo=FALSE, fig.cap="Tidy data",fig.align='center',out.width="80%"}
knitr::include_graphics('figure/tidy1.png')
```

---
#Tidy Data
## The principles
2. Each observation must have its own row.

```{r echo=FALSE, fig.cap="Messy data",fig.align='center',out.width="80%"}
knitr::include_graphics('figure/untidy2.png')
```

```{r echo=FALSE, fig.cap="Tidy data",fig.align='center',out.width="80%"}
knitr::include_graphics('figure/tidy2.png')
```

---
#Tidy Data
## The principles
2. Each observation must have its own row.

An alternative
```{r echo=FALSE, fig.cap="Messy data",fig.align='center',out.width="80%"}
knitr::include_graphics('figure/tidy2-alt.png')
```
---
#Tidy Data
## The principles
3. Each value must have its own cell.

```{r echo=FALSE, fig.cap="Messy data",fig.align='center',out.width="30%"}
knitr::include_graphics('figure/untidy3.png')
```

```{r echo=FALSE, fig.cap="Tidy data",fig.align='center',out.width="30%"}
knitr::include_graphics('figure/tidy3.png')
```

---

class: inverse, center, middle
# DATA ANALYTICS
---
# Data Analytics

- Data Analytics

   - Includes data analysis as subcomponent.
   
   - Look forward to model a future or predict a result.
   
   - Steps include collect, store, process, analyse, find patterns.
   
- Big Data Analytics

   - Using data analytics to process massive amount of data (big data)

---
class: inverse, center, middle

# BIG DATA ANALYTICS
## The Types

---

# Types of Big Data Analytics

1. Descriptive Analytics
   - Explain to what happen in the past based on data through descriptive statistics and data visualisation.
   
2. Diagnostic Analytics
   - Related to descriptive analytics and seek to understand reason why any given event took place in the past.
   
3. Predictive Analytics
   - The most useful type that can be used to predict what could happen. 

4. Prescriptive Analytics
   - Evolution of preceeding approaches based on automation processing of prediction and determine the actions to be taken.

---

class: inverse, center, middle
# DATA VISUALISATION
---
#Data Visualisation
.pull-left[
- involves the presentation of data of almost any type in a graphical format that makes it easy to understand and interpret. 

- relies on powerful computer systems to ingest raw corporate data and process it to generate graphical representations that allow humans to take in and understand vast amounts of data in seconds.
]
.pull-right[
```{r echo=FALSE, fig.cap="Tidy data",fig.align='center'}
knitr::include_graphics('figure/LinkedIn-map.jpg')
```
]
---
#Data Visualisation
## The Importance

- Review large amounts of data 
   – gain an understanding of what the data means very quickly – far more quickly than poring over spreadsheets or analyzing numerical tables.

- Spot trends 
   – time-sequence data often captures trends - make it easy to spot these trends, and in business terms a trend that is spotted early is an opportunity that can be acted upon.
   
- Identify correlations and unexpected relationships  
   - to discover what unexpected insights the data can reveal. 
   
- Present the data to others 
   – It provides a highly effective way to communicate any insights that it surfaces to others. That's because it can convey meaning very quickly and in a way that it is easy to understand.
---

# Learning Outcomes

## Now you should be able to:

1. describe the big data, data science and related concepts. 

2. describe the application of data science in related fields and healthcare.

3. differentiate between statistical analysis, data analysis and big data analytics.

4. describe the data analysis workflow and the principles of tidy data.

5. explain the types of big data analytics.


---

class: center, middle

# Thanks!

Slides created via the R package [**xaringan**](https://github.com/yihui/xaringan).

